{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data & Things (RUC F2023)\n",
    "\n",
    "## Hand-in Exercises for Exam\n",
    "\n",
    "* This is a template for your exercise solutions. Each solution may use multiple cells. \n",
    "\n",
    "* Do your best to make your code clean and clear, e.g., by using comments and markdowns.\n",
    "\n",
    "* Remeber to fill in the information of all your group members in the following cell."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Members:\n",
    "* [Rasmus Kjær Nielsen, 68910, rkjaern@ruc.dk]\n",
    "* [name_2, student number, email_2]\n",
    "* [Add more if needed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Loading of common modules or initialization of other common things, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scratch.deep_learning as dl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EDA and data cleaning (Lecture 2 & 5)\n",
    "\n",
    "Make an Exploratory Data Analysis (EDA) and data cleaning of the “titanic_survival_data.csv” dataset from Lectures 5 and 6, including dealing with outliers and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"data/titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Cabin\"].fillna(\"Unknown\", inplace=True)\n",
    "titanic.dropna(subset=[\"Age\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare    Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500  Unknown        S  \n",
       "1      0          PC 17599  71.2833      C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250  Unknown        S  \n",
       "3      0            113803  53.1000     C123        S  \n",
       "4      0            373450   8.0500  Unknown        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Sex\"] = titanic.Sex.replace({'male':0, 'female':1})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible values for PClass: [3 1 2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived                                               Name  \\\n",
       "0            1         0                            Braund, Mr. Owen Harris   \n",
       "1            2         1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3         1                             Heikkinen, Miss. Laina   \n",
       "3            4         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5         0                           Allen, Mr. William Henry   \n",
       "\n",
       "   Sex   Age  SibSp  Parch            Ticket     Fare    Cabin Embarked  \\\n",
       "0    0  22.0      1      0         A/5 21171   7.2500  Unknown        S   \n",
       "1    1  38.0      1      0          PC 17599  71.2833      C85        C   \n",
       "2    1  26.0      0      0  STON/O2. 3101282   7.9250  Unknown        S   \n",
       "3    1  35.0      1      0            113803  53.1000     C123        S   \n",
       "4    0  35.0      0      0            373450   8.0500  Unknown        S   \n",
       "\n",
       "   Pclass_1  Pclass_2  Pclass_3  Pclass  \n",
       "0         0         0         1       3  \n",
       "1         1         0         0       1  \n",
       "2         0         0         1       3  \n",
       "3         1         0         0       1  \n",
       "4         0         0         1       3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all possible categories for the \"PClass\" column\n",
    "print(f\"Possible values for PClass: {titanic['Pclass'].unique()}\")\n",
    "\n",
    "# Use Pandas to One-Hot encode the PClass category\n",
    "dataset_with_one_hot = pd.get_dummies(titanic, columns=[\"Pclass\"], drop_first=False)\n",
    "\n",
    "# Add back in the old Pclass column, for learning purposes\n",
    "dataset_with_one_hot[\"Pclass\"] = titanic.Pclass\n",
    "\n",
    "# Print out the first few rows\n",
    "dataset_with_one_hot.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same principle. We convert from cabin number and narrow it down to corresponding deck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 cabins found\n"
     ]
    }
   ],
   "source": [
    "dataset_with_one_hot = pd.get_dummies(titanic, columns=[\"Pclass\", \"Cabin\"], drop_first=False)\n",
    "\n",
    "cabin_column_names = list(c for c in dataset_with_one_hot.columns if c.startswith(\"Cabin_\"))\n",
    "\n",
    "print(len(cabin_column_names), \"cabins found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decks:  ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T', 'U']\n"
     ]
    }
   ],
   "source": [
    "titanic[\"Deck\"] = [c[0] for c in titanic.Cabin]\n",
    "\n",
    "print(\"Decks: \", sorted(titanic.Deck.unique()))\n",
    "\n",
    "dataset_with_one_hot = pd.get_dummies(titanic, columns=[\"Pclass\", \"Deck\"], drop_first=False)\n",
    "\n",
    "deck_of_cabin_column_names = list(c for c in dataset_with_one_hot.columns if c.startswith(\"Deck_\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Deck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>S</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>S</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>S</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    0  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    1  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    0  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare    Cabin Embarked Deck  \n",
       "0         A/5 21171   7.2500  Unknown        S    U  \n",
       "1          PC 17599  71.2833      C85        C    C  \n",
       "2  STON/O2. 3101282   7.9250  Unknown        S    U  \n",
       "3            113803  53.1000     C123        S    C  \n",
       "4            373450   8.0500  Unknown        S    U  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification (Lecture 3 & 4)\n",
    "\n",
    "Combine the exercise from Lecture 3 with exercise 2 from Lecture 4 into one, and construct some classification models to predict if a passenger would survive or not in the Titanic dataset. \n",
    "\n",
    "* a) You should have (1) decision tree, (2) random forest, and (3) KNN. You may also vary the configuration of each model type.\n",
    "* b) You should do necessary data preprocessing (e.g., missing value fill-in, and data scaling if needed for a classifier). \n",
    "* c) You should also do cross-validation of your models.\n",
    "* d) Plot the ROC with AUC for each model you implement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regression (Lecture 6)\n",
    "\n",
    "Train a multiple linear regression, a random forest model, and an AdaBoost model on the “boston_housing_data.csv” dataset from Lectures 5 and 6 and remember to do train-test split as well as other necessary pre-processing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clustering (Lecture 7 & 8)\n",
    "\n",
    "Exercise 2 (both 2.1 and 2.2) from Lecture 7 and exercise 1 from Lecture 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Key-value stores (Lecture 9)\n",
    "\n",
    "Exercise 1 from Lecture 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Deep learning (Lecture 10)\n",
    "\n",
    "Train a deep neural network to predict if a passenger would survive or not in the Titanic dataset and remember to do train-test split as well as other necessary pre-processing dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to use random forrest evaluation find the features that have the most influence towards survivability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Deck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>S</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>S</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>S</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    0  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    1  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    0  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare    Cabin Embarked Deck  \n",
       "0         A/5 21171   7.2500  Unknown        S    U  \n",
       "1          PC 17599  71.2833      C85        C    C  \n",
       "2  STON/O2. 3101282   7.9250  Unknown        S    U  \n",
       "3            113803  53.1000     C123        S    C  \n",
       "4            373450   8.0500  Unknown        S    U  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = titanic.columns.drop(['Survived', 'Name', 'Ticket', 'Cabin', 'Deck', 'Embarked', 'PassengerId'])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic[features]\n",
    "y = titanic['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest: 0.8372093023255814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#criterion='entropy', max_features=5, n_estimators=100, random_state=0)\n",
    "forest = RandomForestClassifier(n_estimators=100, random_state=0) \n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of Random Forest: {}\".format(metrics.accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_feature_importances(model, features):\n",
    "    n_features = len(features)\n",
    "    plt.barh(np.arange(n_features), model.feature_importances_, align='center')\n",
    "    \n",
    "    plt.yticks(np.arange(n_features), features)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature_importances(forest, features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the features with most importance towards predicting survival is Fare, Sex and Age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic[['Age', 'Fare', 'Sex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[24.0, 69.3, 1.0],\n",
       " [17.0, 7.125, 0.0],\n",
       " [34.0, 6.4958, 0.0],\n",
       " [18.0, 79.65, 1.0],\n",
       " [50.0, 106.425, 0.0],\n",
       " [27.0, 211.5, 0.0],\n",
       " [70.0, 71.0, 0.0],\n",
       " [20.0, 7.05, 0.0],\n",
       " [19.0, 14.5, 0.0],\n",
       " [1.0, 39.0, 0.0],\n",
       " [34.0, 21.0, 0.0],\n",
       " [63.0, 9.5875, 1.0],\n",
       " [20.0, 7.925, 0.0],\n",
       " [26.0, 18.7875, 0.0],\n",
       " [45.0, 26.55, 0.0],\n",
       " [33.0, 8.6542, 0.0],\n",
       " [45.0, 26.25, 1.0],\n",
       " [2.0, 26.0, 1.0],\n",
       " [50.0, 55.9, 0.0],\n",
       " [29.0, 21.075, 1.0],\n",
       " [22.0, 7.125, 0.0],\n",
       " [35.0, 53.1, 1.0],\n",
       " [39.0, 0.0, 0.0],\n",
       " [4.0, 16.7, 1.0],\n",
       " [17.0, 8.6625, 0.0],\n",
       " [0.42, 8.5167, 0.0],\n",
       " [1.0, 15.7417, 1.0],\n",
       " [32.0, 56.4958, 0.0],\n",
       " [51.0, 8.05, 0.0],\n",
       " [36.0, 26.0, 1.0],\n",
       " [36.0, 120.0, 0.0],\n",
       " [18.0, 6.75, 1.0],\n",
       " [0.75, 19.2583, 1.0],\n",
       " [18.0, 13.0, 1.0],\n",
       " [29.0, 7.75, 0.0],\n",
       " [36.0, 13.0, 1.0],\n",
       " [54.0, 51.8625, 0.0],\n",
       " [44.0, 90.0, 0.0],\n",
       " [65.0, 61.9792, 0.0],\n",
       " [42.0, 227.525, 1.0],\n",
       " [30.0, 24.0, 0.0],\n",
       " [39.0, 26.0, 0.0],\n",
       " [54.0, 78.2667, 1.0],\n",
       " [29.0, 27.7208, 0.0],\n",
       " [16.0, 10.5, 0.0],\n",
       " [55.0, 30.5, 0.0],\n",
       " [49.0, 76.7292, 1.0],\n",
       " [51.0, 77.9583, 1.0],\n",
       " [31.0, 10.5, 0.0],\n",
       " [19.0, 10.1708, 0.0],\n",
       " [18.0, 8.05, 0.0],\n",
       " [23.0, 263.0, 1.0],\n",
       " [40.5, 14.5, 0.0],\n",
       " [29.0, 26.0, 1.0],\n",
       " [35.0, 8.05, 0.0],\n",
       " [3.0, 41.5792, 1.0],\n",
       " [39.0, 55.9, 1.0],\n",
       " [12.0, 11.2417, 0.0],\n",
       " [40.0, 7.225, 0.0],\n",
       " [36.0, 12.875, 0.0],\n",
       " [3.0, 18.75, 0.0],\n",
       " [48.0, 13.0, 0.0],\n",
       " [60.0, 75.25, 1.0],\n",
       " [17.0, 12.0, 1.0],\n",
       " [20.0, 9.5, 0.0],\n",
       " [19.0, 26.0, 1.0],\n",
       " [29.0, 7.775, 0.0],\n",
       " [21.0, 7.75, 1.0],\n",
       " [27.0, 13.0, 0.0],\n",
       " [22.0, 29.0, 1.0],\n",
       " [39.0, 79.65, 1.0],\n",
       " [40.0, 153.4625, 1.0],\n",
       " [18.0, 7.4958, 1.0],\n",
       " [37.0, 52.5542, 0.0],\n",
       " [9.0, 15.2458, 1.0],\n",
       " [28.0, 7.8958, 1.0],\n",
       " [50.0, 133.65, 0.0],\n",
       " [28.5, 7.2292, 0.0],\n",
       " [9.0, 20.525, 0.0],\n",
       " [25.0, 7.775, 0.0],\n",
       " [11.0, 18.7875, 0.0],\n",
       " [28.0, 7.8958, 0.0],\n",
       " [31.0, 7.75, 0.0],\n",
       " [24.0, 7.7958, 0.0],\n",
       " [37.0, 9.5875, 1.0],\n",
       " [19.0, 10.5, 0.0],\n",
       " [27.0, 12.475, 1.0],\n",
       " [30.0, 106.425, 1.0],\n",
       " [24.0, 18.75, 1.0],\n",
       " [18.0, 9.8417, 1.0],\n",
       " [20.0, 8.6625, 0.0],\n",
       " [25.0, 30.0, 1.0],\n",
       " [42.0, 8.4042, 0.0],\n",
       " [48.0, 76.7292, 0.0],\n",
       " [16.0, 20.25, 0.0],\n",
       " [24.0, 19.2583, 1.0],\n",
       " [28.0, 22.525, 0.0],\n",
       " [32.0, 7.925, 0.0],\n",
       " [36.0, 512.3292, 0.0],\n",
       " [33.0, 7.8958, 0.0],\n",
       " [26.0, 8.6625, 0.0],\n",
       " [26.0, 10.5, 0.0],\n",
       " [15.0, 7.225, 1.0],\n",
       " [52.0, 30.5, 0.0],\n",
       " [32.5, 13.0, 1.0],\n",
       " [18.0, 108.9, 0.0],\n",
       " [44.0, 16.1, 0.0],\n",
       " [16.0, 8.05, 0.0],\n",
       " [16.0, 9.2167, 0.0],\n",
       " [18.0, 7.775, 0.0],\n",
       " [24.0, 65.0, 1.0],\n",
       " [28.0, 14.4, 1.0],\n",
       " [39.0, 83.1583, 1.0],\n",
       " [50.0, 28.7125, 1.0],\n",
       " [50.0, 13.0, 0.0],\n",
       " [2.0, 21.075, 0.0],\n",
       " [38.0, 153.4625, 0.0],\n",
       " [42.0, 7.65, 0.0],\n",
       " [24.0, 8.85, 1.0],\n",
       " [17.0, 110.8833, 0.0],\n",
       " [25.0, 7.65, 0.0],\n",
       " [42.0, 13.0, 0.0],\n",
       " [23.0, 7.925, 1.0],\n",
       " [30.0, 7.2292, 0.0],\n",
       " [62.0, 26.55, 0.0],\n",
       " [21.0, 16.1, 0.0],\n",
       " [25.0, 17.8, 0.0],\n",
       " [35.0, 512.3292, 0.0],\n",
       " [26.0, 7.925, 1.0],\n",
       " [38.0, 7.05, 0.0],\n",
       " [35.0, 135.6333, 1.0],\n",
       " [38.0, 80.0, 1.0],\n",
       " [51.0, 26.55, 0.0],\n",
       " [65.0, 7.75, 0.0],\n",
       " [34.0, 13.0, 0.0],\n",
       " [24.0, 7.05, 0.0],\n",
       " [19.0, 8.05, 0.0],\n",
       " [30.0, 7.25, 0.0],\n",
       " [16.0, 9.5, 0.0],\n",
       " [4.0, 23.0, 1.0],\n",
       " [27.0, 76.7292, 0.0],\n",
       " [51.0, 7.75, 0.0],\n",
       " [15.0, 7.2292, 0.0],\n",
       " [62.0, 80.0, 1.0],\n",
       " [52.0, 13.5, 0.0],\n",
       " [45.0, 164.8667, 1.0],\n",
       " [0.75, 19.2583, 1.0],\n",
       " [24.0, 247.5208, 0.0],\n",
       " [36.0, 10.5, 0.0],\n",
       " [27.0, 7.8958, 0.0],\n",
       " [21.0, 7.7333, 0.0],\n",
       " [35.0, 7.05, 0.0],\n",
       " [48.0, 39.6, 1.0],\n",
       " [25.0, 13.0, 0.0],\n",
       " [18.0, 11.5, 0.0],\n",
       " [80.0, 30.0, 0.0],\n",
       " [39.0, 29.125, 1.0],\n",
       " [9.0, 31.275, 1.0],\n",
       " [7.0, 39.6875, 0.0],\n",
       " [24.0, 27.0, 1.0],\n",
       " [36.0, 27.75, 0.0],\n",
       " [24.0, 73.5, 0.0],\n",
       " [30.0, 16.1, 0.0],\n",
       " [17.0, 108.9, 1.0],\n",
       " [63.0, 77.9583, 1.0],\n",
       " [30.0, 56.9292, 1.0],\n",
       " [29.0, 7.8958, 0.0],\n",
       " [53.0, 51.4792, 1.0],\n",
       " [28.0, 10.5, 0.0],\n",
       " [23.0, 13.0, 0.0],\n",
       " [64.0, 263.0, 0.0],\n",
       " [26.0, 26.0, 1.0],\n",
       " [22.0, 66.6, 1.0],\n",
       " [41.0, 7.125, 0.0],\n",
       " [32.0, 15.85, 0.0],\n",
       " [36.0, 120.0, 1.0],\n",
       " [25.0, 26.0, 0.0],\n",
       " [24.0, 16.1, 0.0],\n",
       " [23.5, 7.2292, 0.0],\n",
       " [21.0, 7.65, 1.0],\n",
       " [22.0, 41.5792, 1.0],\n",
       " [25.0, 55.4417, 0.0],\n",
       " [28.0, 7.7958, 0.0],\n",
       " [20.0, 7.8542, 0.0],\n",
       " [25.0, 7.25, 0.0],\n",
       " [30.0, 93.5, 1.0],\n",
       " [54.0, 77.2875, 0.0],\n",
       " [8.0, 36.75, 0.0],\n",
       " [27.0, 8.6625, 0.0],\n",
       " [34.0, 26.55, 0.0],\n",
       " [14.0, 11.2417, 1.0],\n",
       " [18.0, 20.2125, 0.0],\n",
       " [2.0, 31.275, 1.0],\n",
       " [30.0, 8.05, 0.0],\n",
       " [6.0, 12.475, 0.0],\n",
       " [38.0, 71.2833, 1.0],\n",
       " [22.0, 49.5, 1.0],\n",
       " [42.0, 52.0, 0.0],\n",
       " [17.0, 14.4583, 1.0],\n",
       " [18.0, 73.5, 0.0],\n",
       " [59.0, 7.25, 0.0],\n",
       " [18.0, 13.0, 0.0],\n",
       " [32.0, 15.5, 1.0],\n",
       " [30.0, 13.0, 0.0],\n",
       " [40.5, 7.75, 0.0],\n",
       " [36.0, 7.4958, 0.0],\n",
       " [48.0, 52.0, 0.0],\n",
       " [60.0, 39.0, 0.0],\n",
       " [35.0, 7.125, 0.0],\n",
       " [70.5, 7.75, 0.0],\n",
       " [26.0, 16.1, 1.0],\n",
       " [47.0, 38.5, 0.0],\n",
       " [54.0, 23.0, 1.0],\n",
       " [51.0, 61.3792, 0.0],\n",
       " [30.0, 8.6625, 1.0],\n",
       " [27.0, 13.8583, 1.0],\n",
       " [47.0, 34.0208, 0.0],\n",
       " [23.0, 113.275, 1.0],\n",
       " [33.0, 27.75, 1.0],\n",
       " [39.0, 31.275, 0.0],\n",
       " [18.0, 7.75, 0.0],\n",
       " [4.0, 39.0, 1.0],\n",
       " [32.0, 7.75, 0.0],\n",
       " [25.0, 13.0, 0.0],\n",
       " [25.0, 7.225, 0.0],\n",
       " [24.0, 7.8958, 0.0],\n",
       " [19.0, 6.75, 0.0],\n",
       " [27.0, 10.5, 1.0],\n",
       " [1.0, 46.9, 0.0],\n",
       " [24.0, 7.4958, 0.0],\n",
       " [30.0, 13.0, 0.0],\n",
       " [35.0, 8.05, 0.0],\n",
       " [55.0, 16.0, 1.0],\n",
       " [30.0, 31.0, 1.0],\n",
       " [16.0, 46.9, 1.0],\n",
       " [11.0, 31.275, 1.0],\n",
       " [35.0, 512.3292, 1.0],\n",
       " [28.0, 26.55, 0.0],\n",
       " [22.0, 7.775, 1.0],\n",
       " [17.0, 8.6625, 0.0],\n",
       " [29.0, 7.0458, 0.0],\n",
       " [42.0, 27.0, 0.0],\n",
       " [22.0, 151.55, 1.0],\n",
       " [8.0, 26.25, 1.0],\n",
       " [41.0, 134.5, 1.0],\n",
       " [36.0, 26.2875, 0.0],\n",
       " [21.0, 77.9583, 1.0],\n",
       " [55.5, 8.05, 0.0],\n",
       " [1.0, 11.1333, 1.0],\n",
       " [43.0, 6.45, 0.0],\n",
       " [17.0, 7.925, 1.0],\n",
       " [37.0, 29.7, 0.0],\n",
       " [22.0, 7.75, 1.0],\n",
       " [16.0, 57.9792, 1.0],\n",
       " [28.0, 13.0, 0.0],\n",
       " [45.0, 35.5, 0.0],\n",
       " [19.0, 26.0, 1.0],\n",
       " [40.0, 134.5, 1.0],\n",
       " [19.0, 10.5, 0.0],\n",
       " [29.0, 26.0, 1.0],\n",
       " [22.0, 7.25, 1.0],\n",
       " [28.0, 13.5, 0.0],\n",
       " [56.0, 83.1583, 1.0],\n",
       " [14.0, 39.6875, 0.0],\n",
       " [2.0, 151.55, 1.0],\n",
       " [30.0, 9.5, 0.0],\n",
       " [19.0, 7.8542, 1.0],\n",
       " [20.0, 8.6625, 1.0],\n",
       " [41.0, 20.2125, 1.0],\n",
       " [32.0, 7.925, 0.0],\n",
       " [70.0, 10.5, 0.0],\n",
       " [24.0, 69.3, 1.0],\n",
       " [36.0, 7.8958, 0.0],\n",
       " [58.0, 146.5208, 1.0],\n",
       " [60.0, 79.2, 0.0],\n",
       " [2.0, 10.4625, 1.0],\n",
       " [40.0, 31.0, 0.0],\n",
       " [48.0, 65.0, 1.0],\n",
       " [29.0, 15.2458, 1.0],\n",
       " [5.0, 31.3875, 1.0],\n",
       " [23.0, 10.5, 0.0],\n",
       " [21.0, 9.825, 1.0],\n",
       " [9.0, 31.3875, 0.0],\n",
       " [24.0, 13.0, 1.0],\n",
       " [28.0, 7.8542, 0.0],\n",
       " [58.0, 153.4625, 1.0],\n",
       " [29.0, 10.5, 0.0],\n",
       " [29.0, 10.4625, 1.0],\n",
       " [22.0, 135.6333, 0.0],\n",
       " [18.0, 11.5, 0.0],\n",
       " [31.0, 26.25, 1.0],\n",
       " [26.0, 7.8542, 0.0],\n",
       " [24.0, 9.5, 0.0],\n",
       " [21.0, 77.2875, 0.0],\n",
       " [30.0, 8.05, 0.0],\n",
       " [27.0, 53.1, 0.0],\n",
       " [32.0, 76.2917, 1.0],\n",
       " [31.0, 7.775, 0.0],\n",
       " [33.0, 8.6625, 0.0],\n",
       " [49.0, 110.8833, 0.0],\n",
       " [24.0, 7.1417, 0.0],\n",
       " [45.0, 14.4542, 1.0],\n",
       " [36.0, 17.4, 1.0],\n",
       " [35.0, 7.8958, 0.0],\n",
       " [32.0, 10.5, 0.0],\n",
       " [21.0, 7.25, 0.0],\n",
       " [48.0, 25.9292, 1.0],\n",
       " [26.0, 30.0, 0.0],\n",
       " [43.0, 26.25, 0.0],\n",
       " [51.0, 7.0542, 0.0],\n",
       " [44.0, 8.05, 0.0],\n",
       " [45.0, 8.05, 0.0],\n",
       " [11.0, 46.9, 0.0],\n",
       " [24.0, 15.85, 1.0],\n",
       " [40.0, 27.7208, 0.0],\n",
       " [52.0, 79.65, 0.0],\n",
       " [35.0, 21.0, 1.0],\n",
       " [58.0, 113.275, 0.0],\n",
       " [27.0, 21.0, 1.0],\n",
       " [37.0, 53.1, 0.0],\n",
       " [61.0, 33.5, 0.0],\n",
       " [21.0, 7.775, 0.0],\n",
       " [45.0, 7.75, 1.0],\n",
       " [21.0, 8.05, 0.0],\n",
       " [38.0, 13.0, 1.0],\n",
       " [21.0, 73.5, 0.0],\n",
       " [46.0, 79.2, 0.0],\n",
       " [27.0, 6.975, 0.0],\n",
       " [4.0, 27.9, 0.0],\n",
       " [28.0, 24.0, 1.0],\n",
       " [18.0, 7.7958, 0.0],\n",
       " [36.0, 15.55, 0.0],\n",
       " [31.0, 57.0, 0.0],\n",
       " [28.0, 47.1, 0.0],\n",
       " [32.0, 7.8958, 0.0],\n",
       " [50.0, 8.05, 0.0],\n",
       " [42.0, 7.55, 0.0],\n",
       " [39.0, 7.925, 0.0],\n",
       " [62.0, 10.5, 0.0],\n",
       " [26.0, 78.85, 1.0],\n",
       " [36.0, 40.125, 0.0],\n",
       " [7.0, 26.25, 1.0],\n",
       " [1.0, 20.575, 0.0],\n",
       " [19.0, 7.775, 0.0],\n",
       " [16.0, 26.0, 0.0],\n",
       " [41.0, 19.5, 1.0],\n",
       " [43.0, 211.3375, 1.0],\n",
       " [18.0, 6.4958, 0.0],\n",
       " [8.0, 21.075, 1.0],\n",
       " [23.0, 11.5, 0.0],\n",
       " [28.0, 15.85, 0.0],\n",
       " [24.0, 14.5, 1.0],\n",
       " [32.0, 7.8542, 0.0],\n",
       " [4.0, 29.125, 0.0],\n",
       " [43.0, 46.9, 1.0],\n",
       " [40.0, 0.0, 0.0],\n",
       " [21.0, 11.5, 0.0],\n",
       " [18.0, 8.3, 0.0],\n",
       " [10.0, 27.9, 0.0],\n",
       " [41.0, 39.6875, 1.0],\n",
       " [29.0, 211.3375, 1.0],\n",
       " [22.0, 7.8958, 0.0],\n",
       " [26.0, 56.4958, 0.0],\n",
       " [19.0, 7.65, 0.0],\n",
       " [22.0, 7.7958, 0.0],\n",
       " [20.5, 7.25, 0.0],\n",
       " [16.0, 7.775, 0.0],\n",
       " [20.0, 7.2292, 0.0],\n",
       " [34.0, 14.4, 0.0],\n",
       " [24.0, 13.0, 1.0],\n",
       " [28.0, 35.5, 0.0],\n",
       " [22.0, 7.25, 0.0],\n",
       " [16.0, 86.5, 1.0],\n",
       " [38.0, 0.0, 0.0],\n",
       " [29.0, 9.4833, 0.0],\n",
       " [30.0, 10.5, 0.0],\n",
       " [34.0, 21.0, 0.0],\n",
       " [25.0, 7.775, 1.0],\n",
       " [37.0, 26.0, 0.0],\n",
       " [23.0, 7.8958, 0.0],\n",
       " [45.5, 28.5, 0.0],\n",
       " [21.0, 7.8542, 0.0],\n",
       " [26.0, 7.775, 0.0],\n",
       " [29.0, 7.875, 0.0],\n",
       " [33.0, 86.5, 1.0],\n",
       " [27.0, 14.4542, 0.0],\n",
       " [6.0, 33.0, 1.0],\n",
       " [33.0, 12.275, 0.0],\n",
       " [56.0, 30.6958, 0.0],\n",
       " [44.0, 57.9792, 1.0],\n",
       " [35.0, 26.55, 0.0],\n",
       " [19.0, 13.0, 0.0],\n",
       " [11.0, 120.0, 0.0],\n",
       " [58.0, 26.55, 1.0],\n",
       " [29.0, 66.6, 0.0],\n",
       " [32.5, 30.0708, 0.0],\n",
       " [3.0, 31.3875, 0.0],\n",
       " [22.0, 10.5167, 1.0],\n",
       " [38.0, 227.525, 1.0],\n",
       " [4.0, 13.4167, 1.0],\n",
       " [34.5, 6.4375, 0.0],\n",
       " [31.0, 13.0, 0.0],\n",
       " [23.0, 7.8542, 0.0],\n",
       " [44.0, 7.925, 0.0],\n",
       " [23.0, 63.3583, 0.0],\n",
       " [34.0, 26.0, 0.0],\n",
       " [36.0, 13.0, 1.0],\n",
       " [40.0, 15.5, 0.0],\n",
       " [0.83, 18.75, 0.0],\n",
       " [18.0, 23.0, 1.0],\n",
       " [20.0, 7.925, 0.0],\n",
       " [47.0, 7.25, 0.0],\n",
       " [24.0, 49.5042, 1.0],\n",
       " [54.0, 26.0, 0.0],\n",
       " [24.0, 26.0, 1.0],\n",
       " [34.0, 8.05, 0.0],\n",
       " [28.0, 12.65, 1.0],\n",
       " [32.0, 13.0, 1.0],\n",
       " [20.0, 4.0125, 0.0],\n",
       " [44.0, 26.0, 0.0],\n",
       " [48.0, 34.375, 1.0],\n",
       " [14.0, 120.0, 1.0],\n",
       " [0.92, 151.55, 0.0],\n",
       " [22.0, 8.05, 0.0],\n",
       " [39.0, 24.15, 0.0],\n",
       " [50.0, 10.5, 1.0],\n",
       " [40.0, 27.9, 0.0],\n",
       " [16.0, 7.75, 1.0],\n",
       " [19.0, 53.1, 0.0],\n",
       " [47.0, 52.5542, 1.0],\n",
       " [44.0, 27.7208, 1.0],\n",
       " [28.0, 13.0, 1.0],\n",
       " [22.0, 7.5208, 0.0],\n",
       " [40.0, 13.0, 1.0],\n",
       " [16.0, 7.7333, 1.0],\n",
       " [38.0, 31.3875, 1.0],\n",
       " [57.0, 10.5, 1.0],\n",
       " [23.0, 9.225, 0.0],\n",
       " [36.0, 24.15, 0.0],\n",
       " [50.0, 10.5, 1.0],\n",
       " [66.0, 10.5, 0.0],\n",
       " [30.0, 7.225, 0.0],\n",
       " [17.0, 10.5, 1.0],\n",
       " [2.0, 29.125, 0.0],\n",
       " [22.0, 8.05, 0.0],\n",
       " [19.0, 8.05, 0.0],\n",
       " [13.0, 7.2292, 1.0],\n",
       " [10.0, 24.15, 1.0],\n",
       " [28.0, 82.1708, 0.0],\n",
       " [36.0, 78.85, 0.0],\n",
       " [5.0, 27.75, 1.0],\n",
       " [26.0, 7.8958, 0.0],\n",
       " [21.0, 8.4333, 0.0],\n",
       " [18.0, 9.35, 1.0],\n",
       " [45.0, 13.5, 1.0],\n",
       " [16.0, 8.05, 0.0],\n",
       " [35.0, 90.0, 1.0],\n",
       " [46.0, 61.175, 0.0],\n",
       " [25.0, 41.5792, 0.0],\n",
       " [34.0, 13.0, 1.0],\n",
       " [49.0, 25.9292, 1.0],\n",
       " [32.0, 26.0, 0.0],\n",
       " [8.0, 29.125, 0.0],\n",
       " [31.0, 37.0042, 0.0],\n",
       " [31.0, 20.525, 1.0],\n",
       " [50.0, 26.0, 1.0],\n",
       " [24.0, 16.7, 1.0],\n",
       " [23.0, 7.55, 1.0],\n",
       " [21.0, 7.7958, 0.0],\n",
       " [24.5, 8.05, 0.0],\n",
       " [46.0, 26.0, 0.0],\n",
       " [27.0, 11.1333, 1.0],\n",
       " [71.0, 49.5042, 0.0],\n",
       " [18.0, 7.8542, 0.0],\n",
       " [14.5, 14.4542, 1.0],\n",
       " [30.0, 7.8958, 0.0],\n",
       " [32.0, 7.925, 0.0],\n",
       " [25.0, 7.775, 0.0],\n",
       " [25.0, 7.925, 1.0],\n",
       " [42.0, 26.2875, 0.0],\n",
       " [17.0, 8.6625, 0.0],\n",
       " [21.0, 8.6625, 0.0],\n",
       " [42.0, 52.5542, 0.0],\n",
       " [26.0, 7.8542, 1.0],\n",
       " [52.0, 78.2667, 1.0],\n",
       " [4.0, 81.8583, 0.0],\n",
       " [54.0, 14.0, 0.0],\n",
       " [25.0, 13.0, 0.0],\n",
       " [27.0, 13.0, 0.0],\n",
       " [42.0, 8.6625, 0.0],\n",
       " [9.0, 15.9, 0.0],\n",
       " [2.0, 27.9, 1.0],\n",
       " [23.0, 13.0, 0.0],\n",
       " [40.0, 15.75, 1.0],\n",
       " [36.0, 0.0, 0.0],\n",
       " [39.0, 13.0, 0.0],\n",
       " [26.0, 20.575, 0.0],\n",
       " [19.0, 91.0792, 1.0],\n",
       " [21.0, 7.8, 0.0]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.values.tolist()\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "641    1\n",
       "433    0\n",
       "202    0\n",
       "585    1\n",
       "544    0\n",
       "      ..\n",
       "179    0\n",
       "808    0\n",
       "93     0\n",
       "291    1\n",
       "51     0\n",
       "Name: Survived, Length: 499, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_oh = [dl.one_hot_encode(y, 2) for y in y_train]\n",
    "y_train_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_oh = [dl.one_hot_encode(y, 2) for y in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "    \n",
    "# Name them so we can turn train on and off\n",
    "dropout1 = dl.Dropout(0.1)\n",
    "dropout2 = dl.Dropout(0.1)\n",
    "dropout3 = dl.Dropout(0.1)\n",
    "    \n",
    "t_model = dl.Sequential([\n",
    "    dl.Linear(3, 32),  # Hidden layer 1: size 32\n",
    "    dropout1,\n",
    "    dl.Tanh(),\n",
    "    dl.Linear(32, 16),   # Hidden layer 2: size 16\n",
    "    dropout2,\n",
    "    dl.Tanh(),\n",
    "    dl.Linear(16, 8),   # Hidden layer 3: size 8\n",
    "    dropout3,\n",
    "    dl.Tanh(),\n",
    "    dl.Linear(8, 2)    # Output layer: size 2\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "import tqdm\n",
    "def loop(model: dl.Layer,\n",
    "             images: dl.List[dl.Tensor],\n",
    "             labels: dl.List[dl.Tensor],\n",
    "             loss: dl.Loss,\n",
    "             optimizer: dl.Optimizer = None) -> None:\n",
    "        correct = 0         # Track number of correct predictions.\n",
    "        total_loss = 0.0    # Track total loss.\n",
    "    \n",
    "        with tqdm.trange(len(images)) as t:\n",
    "            for i in t:\n",
    "                predicted = model.forward(images[i])             # Predict.\n",
    "                if argmax(predicted) == argmax(labels[i]):       # Check for\n",
    "                    correct += 1                                 # correctness.\n",
    "                total_loss += loss.loss(predicted, labels[i])    # Compute loss.\n",
    "    \n",
    "                # If we're training, backpropagate gradient and update weights.\n",
    "                if optimizer is not None:\n",
    "                    gradient = loss.gradient(predicted, labels[i])\n",
    "                    model.backward(gradient)\n",
    "                    optimizer.step(model)\n",
    "    \n",
    "                # And update our metrics in the progress bar.\n",
    "                avg_loss = total_loss / (i + 1)\n",
    "                acc = correct / (i + 1)\n",
    "                t.set_description(f\"mnist loss: {avg_loss:.3f} acc: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mnist loss: 0.675 acc: 0.587: 100%|██████████| 499/499 [00:00<00:00, 1081.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from scratch.deep_learning import main\n",
    "optimizer = dl.Momentum(learning_rate=0.01, momentum=0.99)\n",
    "loss = dl.SoftmaxCrossEntropy()\n",
    "    \n",
    "# Enable dropout and train (takes > 20 minutes on my laptop!)\n",
    "dropout1.train = dropout2.train = dropout3.train = True\n",
    "loop(t_model, X_train, y_train_oh, loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mnist loss: 0.633 acc: 0.623: 100%|██████████| 215/215 [00:00<00:00, 1882.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Disable dropout and evaluate\n",
    "dropout1.train = dropout2.train = dropout3.train = False\n",
    "loop(t_model, X_test, y_test_oh, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.30002447136589044, 0.1555800142473189],\n",
       " [0.3103966983946365, 0.13230022522338208],\n",
       " [0.4369541046131727, -0.00454548363631066],\n",
       " [0.324797928102504, 0.12066359483963987],\n",
       " [0.48201227191616375, -0.06424555832049575],\n",
       " [0.5175036435453675, -0.09732614056127281],\n",
       " [0.4611638224402064, -0.03792938498402759],\n",
       " [0.5130388118694589, -0.09040517326177946],\n",
       " [0.5138789863556682, -0.0938641501121979],\n",
       " [0.4732423099555715, -0.05135622630135353],\n",
       " [0.39952516111384645, 0.039624993546725676],\n",
       " [0.4810745223010457, -0.06223095108585516],\n",
       " [0.525280822584933, -0.1054604667798385],\n",
       " [0.525190688724569, -0.10413298147772629],\n",
       " [0.5106143917399673, -0.09190190599427162],\n",
       " [0.3203381398048842, 0.11341492855737705],\n",
       " [0.47520702021575667, -0.05267252549005333],\n",
       " [0.4885995601049169, -0.07157751859537995],\n",
       " [0.5097995774323234, -0.09181374887068391],\n",
       " [0.5251157598610503, -0.10490057276156822],\n",
       " [0.4736807672640183, -0.05580037450040251],\n",
       " [0.5312934469548424, -0.10945671491032077],\n",
       " [0.30774523760486966, 0.14020233690802142],\n",
       " [0.517222338393004, -0.09476469720626349],\n",
       " [0.5058000391499597, -0.08795490089273034],\n",
       " [0.507440987388945, -0.09448322106969373],\n",
       " [0.526297482815137, -0.10605517073200699],\n",
       " [0.30057508027209423, 0.15555314678884494],\n",
       " [0.30649610943102096, 0.1459481894116046],\n",
       " [0.4682474536522156, -0.04589362468821706],\n",
       " [0.3152347406270307, 0.1393196849323412],\n",
       " [0.5189191905975683, -0.09648645275482592],\n",
       " [0.2970652183639526, 0.1420158009740739],\n",
       " [0.5131930495967408, -0.09502717391653603],\n",
       " [0.3013887314307653, 0.15362551464764257],\n",
       " [0.4936269377636643, -0.08320484490276106],\n",
       " [0.5209618528897187, -0.10183355384537504],\n",
       " [0.3005764576520714, 0.15555473273923395],\n",
       " [0.4554272690939651, -0.02525452143727744],\n",
       " [0.5147721358368995, -0.09443569280670316],\n",
       " [0.4961760922036783, -0.07618022683946166],\n",
       " [0.4781356828560084, -0.05508739937850099],\n",
       " [0.5199334827297653, -0.09914840267304337],\n",
       " [0.5018631932986115, -0.08429261530316645],\n",
       " [0.3062072616746442, 0.14867127129656119],\n",
       " [0.5280026297777579, -0.10621342984131979],\n",
       " [0.3151510350396266, 0.1326165209839699],\n",
       " [0.5100491502432363, -0.08679515416796013],\n",
       " [0.403091429224294, 0.03486647065755294],\n",
       " [0.49375111963044255, -0.07233647629948958],\n",
       " [0.4474124959898167, -0.028059654807232437],\n",
       " [0.3156584927040981, 0.14038219188130582],\n",
       " [0.5112755918342622, -0.09313743236324742],\n",
       " [0.5238734312592744, -0.1041648148695454],\n",
       " [0.5003431547012558, -0.08184849783216874],\n",
       " [0.31654628948030783, 0.1269075029986746],\n",
       " [0.30065981435113753, 0.15550191613140255],\n",
       " [0.3518592940320837, 0.09192679773095594],\n",
       " [0.30162743185962393, 0.13727994210482775],\n",
       " [0.3097714720433517, 0.1281199989015742],\n",
       " [0.4987447078419281, -0.08108881868544995],\n",
       " [0.30235536486486625, 0.13933309116493253],\n",
       " [0.5107992752211754, -0.09255475988588238],\n",
       " [0.4984522492523954, -0.08144543765101542],\n",
       " [0.5003431547012558, -0.08184849783216874],\n",
       " [0.516183025116048, -0.09887621991386669],\n",
       " [0.30414362627348324, 0.1354304363393626],\n",
       " [0.31922686704203107, 0.13379264498629315],\n",
       " [0.29475407958850064, 0.14633923435854163],\n",
       " [0.4967630645943199, -0.07933111314080893],\n",
       " [0.5055313011137126, -0.08556148899457733],\n",
       " [0.48649731287110554, -0.06894324672277785],\n",
       " [0.2942233625211086, 0.14735208854412168],\n",
       " [0.3548397652957661, 0.0844450058155741],\n",
       " [0.39674336111565894, 0.03747047076813026],\n",
       " [0.3986351569688328, 0.04257781867972778],\n",
       " [0.5078700920395143, -0.08947732900036603],\n",
       " [0.5231903467696399, -0.1036205640760802],\n",
       " [0.5180390689523433, -0.0993160027654415],\n",
       " [0.46904569360153436, -0.04875821939136177],\n",
       " [0.47741685541296996, -0.05382758322949005],\n",
       " [0.3850070437413336, 0.0605117977188183],\n",
       " [0.49120451511894814, -0.06467488279334191],\n",
       " [0.33852601358355716, 0.1074407104521716],\n",
       " [0.3004775200632365, 0.15562370010170545],\n",
       " [0.4885995601049169, -0.07157751859537995],\n",
       " [0.4853120285536223, -0.059745276976132855],\n",
       " [0.49913854546368375, -0.08157637082643154],\n",
       " [0.5164588969368181, -0.09324055570929726],\n",
       " [0.42297040136301317, 0.005293669003269996],\n",
       " [0.39371452180266686, 0.048308368503562196],\n",
       " [0.32185339343709995, 0.12499759544546939],\n",
       " [0.3124753430559555, 0.11814508445032254],\n",
       " [0.43557750273656504, -0.001128983474178405],\n",
       " [0.34187928775413556, 0.08956248590017767],\n",
       " [0.31590155720397695, 0.1406870972820116],\n",
       " [0.5251240644346087, -0.10540819242139918],\n",
       " [0.5006494514312851, -0.08289600594323879],\n",
       " [0.5114623639512118, -0.08880708405442983],\n",
       " [0.5121457796621667, -0.09298635089064844],\n",
       " [0.5191047157976638, -0.10025251933518281],\n",
       " [0.5202802245431265, -0.09939165075724923],\n",
       " [0.430730390804985, -0.0019668057589721927],\n",
       " [0.3539374491803623, 0.09890684823128483],\n",
       " [0.3058468407563131, 0.14991933441537006],\n",
       " [0.44152511430461805, -0.022015170742872514],\n",
       " [0.5200414661027353, -0.10104633950805589],\n",
       " [0.31621621961426577, 0.1407946567022557],\n",
       " [0.3053626913263778, 0.14777255138284462],\n",
       " [0.46727390410326053, -0.0500624250818017],\n",
       " [0.3244990735416398, 0.10536362422673339],\n",
       " [0.43134248853604984, 0.0012641688634400933],\n",
       " [0.4514557630214362, -0.022697864565957626],\n",
       " [0.4546059654305713, -0.026928440764871803],\n",
       " [0.4879300374711196, -0.06733391026996843],\n",
       " [0.32211922924513436, 0.13033319446126787],\n",
       " [0.5092853016255036, -0.08934105890515256],\n",
       " [0.47250957827202655, -0.05432984916943734],\n",
       " [0.3118896228788798, 0.1390755489047137],\n",
       " [0.34871474532548374, 0.10566375348653985],\n",
       " [0.4824697735372233, -0.06394977233946697],\n",
       " [0.3120332982233813, 0.1427276825103687],\n",
       " [0.5130312663896884, -0.09482797636425735],\n",
       " [0.48248082255333813, -0.06483080525057733],\n",
       " [0.4921327967846183, -0.06743085534006293],\n",
       " [0.4958134114620236, -0.07553069385953057],\n",
       " [0.3020615650832855, 0.15352704714400975],\n",
       " [0.4694649762848103, -0.049582383784419176],\n",
       " [0.3233045170163489, 0.12965627273463912],\n",
       " [0.34300626269248297, 0.08564543822897507],\n",
       " [0.46644764222778146, -0.04900846888657612],\n",
       " [0.4886773097769498, -0.07167544503108533],\n",
       " [0.49291403518195764, -0.07529529963225562],\n",
       " [0.46374720804620717, -0.03662717209617816],\n",
       " [0.36992368546098886, 0.07481312361445486],\n",
       " [0.3616530937010718, 0.08481199255229736],\n",
       " [0.3093309636583271, 0.1356121044381286],\n",
       " [0.3120410633148073, 0.1417476296515577],\n",
       " [0.3100933839541079, 0.1457880230596778],\n",
       " [0.4717697497756367, -0.05381972873873564],\n",
       " [0.48455527983533225, -0.06505986262398461],\n",
       " [0.307140227165577, 0.142668647013949],\n",
       " [0.4984522492523954, -0.08144543765101542],\n",
       " [0.40014957164614073, 0.03085861339639895],\n",
       " [0.39346242250051405, 0.045596852850267273],\n",
       " [0.46070562291099915, -0.03153040063426518],\n",
       " [0.503961997011394, -0.08626820724597173],\n",
       " [0.48547514698043576, -0.06794953364828485],\n",
       " [0.4963641229968896, -0.07883540204311354],\n",
       " [0.533242028440205, -0.109928255306144],\n",
       " [0.4558322246069879, -0.030791523076927174],\n",
       " [0.4523178303881605, -0.021756781786078455],\n",
       " [0.4736807672640183, -0.05580037450040251],\n",
       " [0.5142467161023392, -0.0958768676657259],\n",
       " [0.3117825290240834, 0.14343298211252076],\n",
       " [0.3441681519500524, 0.11017756366460339],\n",
       " [0.4784937123253893, -0.06080629825189221],\n",
       " [0.4886642665067968, -0.07165901411490119],\n",
       " [0.5209761824469127, -0.09857701713752276],\n",
       " [0.30252808408715437, 0.1437414413890347],\n",
       " [0.5183478198136577, -0.09933849006878018],\n",
       " [0.47769777524750634, -0.05980911196311972],\n",
       " [0.4673387629608778, -0.04747050689273896],\n",
       " [0.4991186396596813, -0.08155169771609744],\n",
       " [0.5086010164445118, -0.09058939789385675],\n",
       " [0.31159431074587596, 0.12738029871621864],\n",
       " [0.5099463722565233, -0.09073899933138119],\n",
       " [0.47711005974162274, -0.05778663161114375],\n",
       " [0.3156326551727545, 0.1322989372700462],\n",
       " [0.38380426601804757, 0.05922308624217715],\n",
       " [0.5210843821611497, -0.09862958178628606],\n",
       " [0.5249853169174106, -0.10405416439617182],\n",
       " [0.49923749552495433, -0.0801822972419306],\n",
       " [0.519304400543041, -0.09972954491103286],\n",
       " [0.49656643489605506, -0.07663590480263349],\n",
       " [0.5283882438380649, -0.10924326797774478],\n",
       " [0.3325210853319753, 0.11524266924282452],\n",
       " [0.30918654984931027, 0.14484149806231772],\n",
       " [0.40620096984957654, 0.032738571981976786],\n",
       " [0.3064110381223879, 0.13665183248635088],\n",
       " [0.320161035839979, 0.11778638725799635],\n",
       " [0.32390722156393725, 0.12409000985128395],\n",
       " [0.38391751505857913, 0.05676406111365133],\n",
       " [0.3065045766046819, 0.1463067793177475],\n",
       " [0.3057051535759013, 0.14583468123917764],\n",
       " [0.5002819970751164, -0.07672291175145868],\n",
       " [0.5278690893280747, -0.10630302317123289],\n",
       " [0.3017509377444818, 0.15466979576317458],\n",
       " [0.47250447267650725, -0.05334377564963996],\n",
       " [0.5055313011137126, -0.08556148899457733],\n",
       " [0.5039027760553219, -0.08619499754098844],\n",
       " [0.5027602769663536, -0.08425284261221075],\n",
       " [0.4830011221201598, -0.05759051976434765],\n",
       " [0.4944784637952556, -0.07419847003925956],\n",
       " [0.4247575684023081, 0.010559917252884188],\n",
       " [0.3101294878448443, 0.14449434499612213],\n",
       " [0.31569662758155376, 0.1365429761459777],\n",
       " [0.45031216333933943, -0.0193141716811063],\n",
       " [0.4736807672640183, -0.05580037450040251],\n",
       " [0.2957134188935358, 0.14644104559805027],\n",
       " [0.517173129636652, -0.09685623011679273],\n",
       " [0.4997620036147794, -0.07596221791789709],\n",
       " [0.5092379811193836, -0.08559567807069693],\n",
       " [0.5087080913192591, -0.09072635768118364],\n",
       " [0.48248082255333813, -0.06483080525057733],\n",
       " [0.46708357571183406, -0.04905550648509718],\n",
       " [0.3237721715606857, 0.12851060059761565],\n",
       " [0.3952354897751948, 0.039311589128248],\n",
       " [0.47535796761121685, -0.05020313122041248],\n",
       " [0.48972113004193624, -0.06512012334734782],\n",
       " [0.38419536135326016, 0.05194543061389767],\n",
       " [0.3270796879981348, 0.1259668336387001],\n",
       " [0.5093360089676806, -0.0912304990155548],\n",
       " [0.48289074928363707, -0.05908494423884547],\n",
       " [0.30031695057618457, 0.15553381937594846]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = [t_model.forward(x) for x in X_test]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5360484592050708, 0.4639515407949291],\n",
       " [0.5444068044012288, 0.45559319559877115],\n",
       " [0.6086162945414282, 0.3913837054585718],\n",
       " [0.5508571010644228, 0.44914289893557724],\n",
       " [0.6332669440127195, 0.36673305598728057],\n",
       " [0.6490417523361469, 0.35095824766385303],\n",
       " [0.6222462079286373, 0.3777537920713626],\n",
       " [0.6464438399128323, 0.3535561600871678],\n",
       " [0.6474258092699093, 0.3525741907300907],\n",
       " [0.6282224276491088, 0.3717775723508911],\n",
       " [0.5890162672270277, 0.4109837327729723],\n",
       " [0.6325810195094544, 0.36741898049054555],\n",
       " [0.6526575282999026, 0.3473424717000973],\n",
       " [0.6523360906526599, 0.34766390934734015],\n",
       " [0.6462317842669141, 0.35376821573308587],\n",
       " [0.5515470089820834, 0.44845299101791664],\n",
       " [0.6289884140278108, 0.37101158597218914],\n",
       " [0.6364935118858516, 0.3635064881141485],\n",
       " [0.6460253230629064, 0.35397467693709356],\n",
       " [0.6524931655561126, 0.3475068344438874],\n",
       " [0.6293620883934297, 0.37063791160657045],\n",
       " [0.6549230160293184, 0.3450769839706816],\n",
       " [0.5417880195620884, 0.45821198043791156],\n",
       " [0.6483939384090376, 0.35160606159096236],\n",
       " [0.6442262387389937, 0.3557737612610064],\n",
       " [0.6460964113110768, 0.35390358868892324],\n",
       " [0.6530227276841535, 0.34697727231584663],\n",
       " [0.5361920748770066, 0.46380792512299335],\n",
       " [0.5400509886353121, 0.45994901136468797],\n",
       " [0.6257767370498277, 0.3742232629501722],\n",
       " [0.5438656995072877, 0.4561343004927124],\n",
       " [0.6491729140696608, 0.3508270859303391],\n",
       " [0.5386848856233208, 0.4613151143766791],\n",
       " [0.6475347041840748, 0.3524652958159252],\n",
       " [0.5368737369309822, 0.4631262630690178],\n",
       " [0.6403380742160124, 0.3596619257839875],\n",
       " [0.6508540529168428, 0.34914594708315716],\n",
       " [0.5361920230076027, 0.4638079769923974],\n",
       " [0.6179088567451895, 0.3820911432548106],\n",
       " [0.6477600759141727, 0.3522399240858272],\n",
       " [0.6393067055011687, 0.3606932944988312],\n",
       " [0.6302345304844938, 0.36976546951550604],\n",
       " [0.6500097089545692, 0.34999029104543067],\n",
       " [0.6424826243915918, 0.35751737560840835],\n",
       " [0.5393027479109752, 0.4606972520890247],\n",
       " [0.653444825288543, 0.346555174711457],\n",
       " [0.5455073442643431, 0.4544926557356568],\n",
       " [0.6449340014015973, 0.35506599859840277],\n",
       " [0.5910299963131371, 0.40897000368686276],\n",
       " [0.6378599191042617, 0.3621400808957383],\n",
       " [0.6166781206085157, 0.38332187939148443],\n",
       " [0.5437072354464935, 0.45629276455350665],\n",
       " [0.646665286420331, 0.35333471357966884],\n",
       " [0.6520445074944247, 0.34795549250557534],\n",
       " [0.6415715494858737, 0.35842845051412636],\n",
       " [0.5472681233430033, 0.4527318766569967],\n",
       " [0.5362258877990637, 0.4637741122009363],\n",
       " [0.5646196978262578, 0.4353803021737422],\n",
       " [0.5409946415118256, 0.45900535848817436],\n",
       " [0.545288403957678, 0.4547115960423219],\n",
       " [0.6410290998914533, 0.35897090010854676],\n",
       " [0.5406655467735546, 0.45933445322644534],\n",
       " [0.6464232811860595, 0.3535767188139404],\n",
       " [0.6410438637528647, 0.3589561362471353],\n",
       " [0.6415715494858737, 0.35842845051412636],\n",
       " [0.6490940186619112, 0.3509059813380888],\n",
       " [0.5420785340266955, 0.4579214659733045],\n",
       " [0.546226170847162, 0.453773829152838],\n",
       " [0.5370357541427494, 0.46296424585725054],\n",
       " [0.6401681823679126, 0.35983181763208744],\n",
       " [0.6436158431877256, 0.3563841568122744],\n",
       " [0.6353969188261814, 0.36460308117381857],\n",
       " [0.536651956700046, 0.46334804329995405],\n",
       " [0.5671898152743405, 0.43281018472565935],\n",
       " [0.5888644099270651, 0.41113559007293493],\n",
       " [0.5880856929060181, 0.4119143070939818],\n",
       " [0.6450492037560698, 0.3549507962439303],\n",
       " [0.651765994698453, 0.3482340053015471],\n",
       " [0.6496167621802312, 0.35038323781976866],\n",
       " [0.6266341044995664, 0.37336589550043375],\n",
       " [0.6297733107254104, 0.3702266892745896],\n",
       " [0.580419385702522, 0.41958061429747795],\n",
       " [0.6354985774369148, 0.3645014225630852],\n",
       " [0.5575156068370856, 0.4424843931629145],\n",
       " [0.5361502664485313, 0.46384973355146875],\n",
       " [0.6364935118858516, 0.3635064881141485],\n",
       " [0.6329880896683819, 0.3670119103316181],\n",
       " [0.6412318919681756, 0.3587681080318243],\n",
       " [0.6478722401181362, 0.3521277598818638],\n",
       " [0.6029271788836099, 0.3970728211163902],\n",
       " [0.5855031415757012, 0.4144968584242989],\n",
       " [0.5490556338883662, 0.4509443661116338],\n",
       " [0.5484302494916226, 0.45156975050837744],\n",
       " [0.6074739731345321, 0.39252602686546795],\n",
       " [0.5627466623978485, 0.4372533376021515],\n",
       " [0.5436918933158833, 0.4563081066841167],\n",
       " [0.6526101400213786, 0.3473898599786214],\n",
       " [0.6418828073544152, 0.35811719264558495],\n",
       " [0.6457179492634437, 0.3542820507365563],\n",
       " [0.6468295771891039, 0.35317042281089595],\n",
       " [0.6500723476284251, 0.3499276523715749],\n",
       " [0.6501439180557907, 0.34985608194420925],\n",
       " [0.6065175498077576, 0.3934824501922424],\n",
       " [0.563414313456173, 0.43658568654382696],\n",
       " [0.5389030863570492, 0.46109691364295086],\n",
       " [0.6138536933886201, 0.3861463066113799],\n",
       " [0.6504659125310296, 0.34953408746897036],\n",
       " [0.5437432732425029, 0.45625672675749696],\n",
       " [0.5393162016285437, 0.4606837983714563],\n",
       " [0.626524700337342, 0.37347529966265797],\n",
       " [0.5545656816485638, 0.4454343183514362],\n",
       " [0.6058923702913168, 0.39410762970868324],\n",
       " [0.6163663919840053, 0.38363360801599455],\n",
       " [0.6181101369261689, 0.381889863073831],\n",
       " [0.6353560025906665, 0.3646439974093336],\n",
       " [0.5478000836778721, 0.4521999163221279],\n",
       " [0.6453419763216739, 0.35465802367832616],\n",
       " [0.6287456574136794, 0.3712543425863207],\n",
       " [0.5430963169448636, 0.4569036830551363],\n",
       " [0.5604653807066236, 0.43953461929337645],\n",
       " [0.6333045000308224, 0.3666954999691776],\n",
       " [0.5422255878504231, 0.4577744121495769],\n",
       " [0.6474523118908598, 0.3525476881091401],\n",
       " [0.6335116434898027, 0.36648835651019723],\n",
       " [0.6363515717927366, 0.3636484282072634],\n",
       " [0.6390732625553976, 0.3609267374446023],\n",
       " [0.5370655080394459, 0.4629344919605541],\n",
       " [0.6269249802674993, 0.3730750197325006],\n",
       " [0.548261339995227, 0.4517386600047731],\n",
       " [0.5639874136857698, 0.43601258631423023],\n",
       " [0.6260846407323565, 0.3739153592676436],\n",
       " [0.6365341570080678, 0.36346584299193213],\n",
       " [0.6383498859192973, 0.3616501140807028],\n",
       " [0.6225473078906527, 0.37745269210934723],\n",
       " [0.5732468201854853, 0.42675317981451466],\n",
       " [0.5687716082698916, 0.4312283917301084],\n",
       " [0.5433208240359882, 0.45667917596401175],\n",
       " [0.5424707708115, 0.4575292291885001],\n",
       " [0.5409841800787725, 0.45901581992122764],\n",
       " [0.628453841718137, 0.37154615828186305],\n",
       " [0.6340462965112535, 0.3659537034887464],\n",
       " [0.5410254554128067, 0.45897454458719333],\n",
       " [0.6410438637528647, 0.3589561362471353],\n",
       " [0.5912876378445073, 0.40871236215549267],\n",
       " [0.5860998896042178, 0.4139001103957821],\n",
       " [0.6206330407027917, 0.3793669592972083],\n",
       " [0.6434179634971828, 0.35658203650281717],\n",
       " [0.6349297774893703, 0.36507022251062976],\n",
       " [0.6399620707093737, 0.36003792929062634],\n",
       " [0.655469755556044, 0.3445302444439559],\n",
       " [0.6193107516775238, 0.38068924832247625],\n",
       " [0.6163477079174804, 0.38365229208251955],\n",
       " [0.6293620883934297, 0.37063791160657045],\n",
       " [0.6479689926934376, 0.35203100730656245],\n",
       " [0.541988265758241, 0.458011734241759],\n",
       " [0.5582321970657632, 0.4417678029342369],\n",
       " [0.6316495673369587, 0.3683504326630413],\n",
       " [0.6365273378793278, 0.36347266212067214],\n",
       " [0.6501169239757852, 0.3498830760242147],\n",
       " [0.5396134637873993, 0.4603865362126008],\n",
       " [0.6496921531599636, 0.3503078468400363],\n",
       " [0.6312322658096011, 0.3687677341903989],\n",
       " [0.6259332011247968, 0.37406679887520317],\n",
       " [0.6412216363659902, 0.3587783636340098],\n",
       " [0.6454710639512304, 0.35452893604876956],\n",
       " [0.5459237087342209, 0.4540762912657791],\n",
       " [0.6458130927860299, 0.3541869072139701],\n",
       " [0.6306244615436396, 0.36937553845636034],\n",
       " [0.5457054829233893, 0.4542945170766107],\n",
       " [0.5804403132387853, 0.41955968676121463],\n",
       " [0.6501534913444319, 0.3498465086555681],\n",
       " [0.6522716356087208, 0.3477283643912793],\n",
       " [0.6409338897337302, 0.3590661102662698],\n",
       " [0.6499988026774408, 0.35000119732255924],\n",
       " [0.6395017694840079, 0.36049823051599206],\n",
       " [0.6542178645533334, 0.34578213544666664],\n",
       " [0.5541069061421235, 0.44589309385787645],\n",
       " [0.540994036116967, 0.459005963883033],\n",
       " [0.5922953501381643, 0.4077046498618357],\n",
       " [0.5423381744219119, 0.457661825578088],\n",
       " [0.5504216923679266, 0.4495783076320734],\n",
       " [0.5497887537700613, 0.4502112462299387],\n",
       " [0.5810666075759143, 0.41893339242408567],\n",
       " [0.5399640183589812, 0.4600359816410188],\n",
       " [0.5398827088366558, 0.4601172911633443],\n",
       " [0.6403779451064558, 0.3596220548935441],\n",
       " [0.6534348731902428, 0.3465651268097572],\n",
       " [0.5367041413699994, 0.4632958586300006],\n",
       " [0.62851426235969, 0.3714857376403099],\n",
       " [0.6436158431877256, 0.3563841568122744],\n",
       " [0.6433875791830369, 0.3566124208169631],\n",
       " [0.6426795235462834, 0.35732047645371656],\n",
       " [0.631950037980905, 0.36804996201909496],\n",
       " [0.6384578285210253, 0.36154217147897466],\n",
       " [0.6020939684562523, 0.3979060315437477],\n",
       " [0.5413143738843578, 0.4586856261156422],\n",
       " [0.5446690019160171, 0.455330998083983],\n",
       " [0.6152953110895535, 0.3847046889104465],\n",
       " [0.6293620883934297, 0.37063791160657045],\n",
       " [0.5372489531491654, 0.4627510468508346],\n",
       " [0.6488594046856175, 0.3511405953143825],\n",
       " [0.6400829574725051, 0.35991704252749485],\n",
       " [0.644473441380886, 0.3555265586191139],\n",
       " [0.6455269064139234, 0.35447309358607665],\n",
       " [0.6335116434898027, 0.36648835651019723],\n",
       " [0.6262445123086909, 0.37375548769130906],\n",
       " [0.5486608827789485, 0.45133911722105147],\n",
       " [0.5880533684701676, 0.41194663152983235],\n",
       " [0.628447215049112, 0.37155278495088795],\n",
       " [0.6352580676887145, 0.3647419323112855],\n",
       " [0.5823067187332845, 0.4176932812667154],\n",
       " [0.5501094319059803, 0.4498905680940197],\n",
       " [0.6457859036271975, 0.35421409637280266],\n",
       " [0.6322718945961499, 0.36772810540385015],\n",
       " [0.5361326865923165, 0.4638673134076835]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.softmax(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_binary = [1 if x[1] > 0.5 else 0 for x in dl.softmax(y_pred)]\n",
    "y_pred_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6232558139534884\n",
      "Recall: 0.0\n",
      "Precision: 0.0\n",
      "Confusion matrix:\n",
      "[[134   0]\n",
      " [ 81   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rasmu\\Documents\\Dev\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_binary))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, y_pred_binary))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred_binary))\n",
    "print(\"Confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mnist loss: 0.653 acc: 0.581: 100%|██████████| 499/499 [00:00<00:00, 1088.04it/s]\n",
      "mnist loss: 0.648 acc: 0.597: 100%|██████████| 499/499 [00:00<00:00, 1121.35it/s]\n",
      "mnist loss: 0.646 acc: 0.619: 100%|██████████| 499/499 [00:00<00:00, 1139.20it/s]\n",
      "mnist loss: 0.635 acc: 0.661: 100%|██████████| 499/499 [00:00<00:00, 1111.85it/s]\n",
      "mnist loss: 0.634 acc: 0.665: 100%|██████████| 499/499 [00:00<00:00, 1075.34it/s]\n",
      "mnist loss: 0.629 acc: 0.683: 100%|██████████| 499/499 [00:00<00:00, 1094.30it/s]\n",
      "mnist loss: 0.626 acc: 0.679: 100%|██████████| 499/499 [00:00<00:00, 1028.00it/s]\n",
      "mnist loss: 0.621 acc: 0.679: 100%|██████████| 499/499 [00:00<00:00, 1050.53it/s]\n",
      "mnist loss: 0.622 acc: 0.683: 100%|██████████| 499/499 [00:00<00:00, 1073.62it/s]\n",
      "mnist loss: 0.623 acc: 0.677: 100%|██████████| 499/499 [00:00<00:00, 1057.20it/s]\n",
      "mnist loss: 0.623 acc: 0.677: 100%|██████████| 499/499 [00:00<00:00, 1059.45it/s]\n",
      "mnist loss: 0.623 acc: 0.677: 100%|██████████| 499/499 [00:00<00:00, 1053.10it/s]\n",
      "mnist loss: 0.626 acc: 0.675: 100%|██████████| 499/499 [00:00<00:00, 1081.06it/s]\n",
      "mnist loss: 0.621 acc: 0.675: 100%|██████████| 499/499 [00:00<00:00, 1087.15it/s]\n",
      "mnist loss: 0.616 acc: 0.675: 100%|██████████| 499/499 [00:00<00:00, 1034.31it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = dl.Momentum(learning_rate=0.001, momentum=0.99)\n",
    "\n",
    "dropout1.train = dropout2.train = dropout3.train = True\n",
    "\n",
    "for _ in range(15):\n",
    "    loop(t_model, X_train, y_train_oh, loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mnist loss: 0.595 acc: 0.702: 100%|██████████| 215/215 [00:00<00:00, 2043.18it/s]\n"
     ]
    }
   ],
   "source": [
    "dropout1.train = dropout2.train = False\n",
    "loop(t_model, X_test, y_test_oh, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [t_model.forward(x) for x in X_test]\n",
    "y_pred_binary = [1 if x[1] > 0.5 else 0 for x in dl.softmax(y_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7116279069767442\n",
      "Recall: 0.6049382716049383\n",
      "Precision: 0.620253164556962\n",
      "Confusion matrix:\n",
      "[[104  30]\n",
      " [ 32  49]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_binary))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, y_pred_binary))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred_binary))\n",
    "print(\"Confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred_binary))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(3)),  # As we have 3 columns in our input data X\n",
    "        layers.Dense(32, activation='tanh'),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(16, activation='tanh'),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(8, activation='tanh'),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(2, activation=\"softmax\")  # Here we specify that we want the last layer to have a softmax activation function\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                128       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 810\n",
      "Trainable params: 810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_keras = np.array(X_train)\n",
    "X_train_keras.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_keras = np.array(y_train_oh)\n",
    "y_train_keras.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "499/499 [==============================] - 1s 547us/step - loss: 0.6732 - accuracy: 0.6052\n",
      "Epoch 2/16\n",
      "499/499 [==============================] - 0s 509us/step - loss: 0.6253 - accuracy: 0.6613\n",
      "Epoch 3/16\n",
      "499/499 [==============================] - 0s 512us/step - loss: 0.6094 - accuracy: 0.6794\n",
      "Epoch 4/16\n",
      "499/499 [==============================] - 0s 504us/step - loss: 0.5954 - accuracy: 0.6994\n",
      "Epoch 5/16\n",
      "499/499 [==============================] - 0s 510us/step - loss: 0.5653 - accuracy: 0.7255\n",
      "Epoch 6/16\n",
      "499/499 [==============================] - 0s 506us/step - loss: 0.5541 - accuracy: 0.7174\n",
      "Epoch 7/16\n",
      "499/499 [==============================] - 0s 508us/step - loss: 0.5551 - accuracy: 0.7234\n",
      "Epoch 8/16\n",
      "499/499 [==============================] - 0s 503us/step - loss: 0.5575 - accuracy: 0.7154\n",
      "Epoch 9/16\n",
      "499/499 [==============================] - 0s 504us/step - loss: 0.5529 - accuracy: 0.7655\n",
      "Epoch 10/16\n",
      "499/499 [==============================] - 0s 505us/step - loss: 0.5330 - accuracy: 0.7575\n",
      "Epoch 11/16\n",
      "499/499 [==============================] - 0s 506us/step - loss: 0.5306 - accuracy: 0.7455\n",
      "Epoch 12/16\n",
      "499/499 [==============================] - 0s 516us/step - loss: 0.5266 - accuracy: 0.7595\n",
      "Epoch 13/16\n",
      "499/499 [==============================] - 0s 562us/step - loss: 0.5262 - accuracy: 0.7655\n",
      "Epoch 14/16\n",
      "499/499 [==============================] - 0s 510us/step - loss: 0.5403 - accuracy: 0.7475\n",
      "Epoch 15/16\n",
      "499/499 [==============================] - 0s 508us/step - loss: 0.5295 - accuracy: 0.7575\n",
      "Epoch 16/16\n",
      "499/499 [==============================] - 0s 526us/step - loss: 0.5188 - accuracy: 0.7735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27eb29e52e0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model.fit(X_train_keras, y_train_keras, batch_size=1, epochs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.4928498864173889\n",
      "Test accuracy: 0.7953488230705261\n"
     ]
    }
   ],
   "source": [
    "score = keras_model.evaluate(np.array(X_test), np.array(y_test_oh), verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 667us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.1558196 , 0.8441804 ],\n",
       "       [0.5646717 , 0.43532827],\n",
       "       [0.23845649, 0.7615435 ],\n",
       "       [0.16399644, 0.8360035 ],\n",
       "       [0.8584647 , 0.14153528],\n",
       "       [0.87188154, 0.12811843],\n",
       "       [0.25275213, 0.7472478 ],\n",
       "       [0.8621902 , 0.13780983],\n",
       "       [0.8705577 , 0.1294423 ],\n",
       "       [0.8433284 , 0.15667161],\n",
       "       [0.76236856, 0.2376315 ],\n",
       "       [0.8551052 , 0.14489476],\n",
       "       [0.87291175, 0.12708819],\n",
       "       [0.8739436 , 0.12605643],\n",
       "       [0.86966574, 0.13033424],\n",
       "       [0.49986342, 0.5001366 ],\n",
       "       [0.843657  , 0.15634304],\n",
       "       [0.8628675 , 0.13713247],\n",
       "       [0.86925465, 0.1307454 ],\n",
       "       [0.8731839 , 0.12681611],\n",
       "       [0.85369396, 0.14630604],\n",
       "       [0.87503254, 0.12496743],\n",
       "       [0.57829726, 0.42170268],\n",
       "       [0.8658035 , 0.13419653],\n",
       "       [0.8682965 , 0.13170356],\n",
       "       [0.86650616, 0.13349389],\n",
       "       [0.873341  , 0.12665902],\n",
       "       [0.3284135 , 0.6715865 ],\n",
       "       [0.5834353 , 0.41656473],\n",
       "       [0.8401019 , 0.15989812],\n",
       "       [0.16472659, 0.8352734 ],\n",
       "       [0.86758596, 0.13241407],\n",
       "       [0.42032403, 0.579676  ],\n",
       "       [0.8699903 , 0.1300097 ],\n",
       "       [0.15726684, 0.84273314],\n",
       "       [0.86293876, 0.13706125],\n",
       "       [0.8718352 , 0.12816478],\n",
       "       [0.15677758, 0.84322244],\n",
       "       [0.8293682 , 0.17063183],\n",
       "       [0.87069947, 0.1293005 ],\n",
       "       [0.26962298, 0.730377  ],\n",
       "       [0.8449624 , 0.15503755],\n",
       "       [0.8727872 , 0.12721287],\n",
       "       [0.86722636, 0.13277356],\n",
       "       [0.16105996, 0.8389401 ],\n",
       "       [0.8748316 , 0.12516843],\n",
       "       [0.5584739 , 0.44152611],\n",
       "       [0.8614632 , 0.13853677],\n",
       "       [0.23467681, 0.76532316],\n",
       "       [0.26062164, 0.73937833],\n",
       "       [0.25217298, 0.74782705],\n",
       "       [0.6011848 , 0.39881516],\n",
       "       [0.8696182 , 0.13038181],\n",
       "       [0.8726471 , 0.12735298],\n",
       "       [0.8660839 , 0.13391607],\n",
       "       [0.16012824, 0.83987176],\n",
       "       [0.15707475, 0.8429252 ],\n",
       "       [0.19158855, 0.8084115 ],\n",
       "       [0.4595071 , 0.54049283],\n",
       "       [0.15139139, 0.8486086 ],\n",
       "       [0.86620456, 0.13379547],\n",
       "       [0.5072118 , 0.4927882 ],\n",
       "       [0.86956674, 0.13043317],\n",
       "       [0.8663237 , 0.13367628],\n",
       "       [0.8660839 , 0.13391607],\n",
       "       [0.8699852 , 0.13001484],\n",
       "       [0.49285   , 0.50714993],\n",
       "       [0.5849381 , 0.41506192],\n",
       "       [0.42226624, 0.5777338 ],\n",
       "       [0.86564076, 0.13435926],\n",
       "       [0.8657097 , 0.1342902 ],\n",
       "       [0.86115277, 0.1388472 ],\n",
       "       [0.42062896, 0.57937104],\n",
       "       [0.18767451, 0.8123255 ],\n",
       "       [0.23065853, 0.7693414 ],\n",
       "       [0.77626294, 0.22373706],\n",
       "       [0.33627307, 0.6637269 ],\n",
       "       [0.8724563 , 0.12754367],\n",
       "       [0.87112826, 0.12887171],\n",
       "       [0.25777146, 0.74222857],\n",
       "       [0.25817305, 0.74182695],\n",
       "       [0.235571  , 0.764429  ],\n",
       "       [0.8562557 , 0.14374425],\n",
       "       [0.17237672, 0.82762325],\n",
       "       [0.1565016 , 0.84349835],\n",
       "       [0.8628675 , 0.13713247],\n",
       "       [0.26605582, 0.73394424],\n",
       "       [0.8663844 , 0.13361567],\n",
       "       [0.8648594 , 0.13514057],\n",
       "       [0.23675975, 0.7632403 ],\n",
       "       [0.23498173, 0.76501834],\n",
       "       [0.5460245 , 0.45397547],\n",
       "       [0.39301142, 0.6069886 ],\n",
       "       [0.23819962, 0.7618004 ],\n",
       "       [0.17165573, 0.8283443 ],\n",
       "       [0.6076028 , 0.39239714],\n",
       "       [0.8728194 , 0.1271806 ],\n",
       "       [0.3203663 , 0.6796337 ],\n",
       "       [0.86124784, 0.13875215],\n",
       "       [0.8701467 , 0.12985334],\n",
       "       [0.8713754 , 0.12862462],\n",
       "       [0.35220248, 0.64779747],\n",
       "       [0.7841562 , 0.21584378],\n",
       "       [0.75486   , 0.24514002],\n",
       "       [0.16294847, 0.8370515 ],\n",
       "       [0.24925917, 0.7507408 ],\n",
       "       [0.8716107 , 0.1283893 ],\n",
       "       [0.16692123, 0.83307874],\n",
       "       [0.5912228 , 0.4087771 ],\n",
       "       [0.8516965 , 0.14830352],\n",
       "       [0.153264  , 0.846736  ],\n",
       "       [0.23759441, 0.76240563],\n",
       "       [0.8231176 , 0.17688242],\n",
       "       [0.24702756, 0.7529725 ],\n",
       "       [0.26148048, 0.73851955],\n",
       "       [0.58607477, 0.41392523],\n",
       "       [0.8681889 , 0.13181111],\n",
       "       [0.85224473, 0.1477553 ],\n",
       "       [0.16185334, 0.8381466 ],\n",
       "       [0.23064165, 0.76935834],\n",
       "       [0.8567945 , 0.14320551],\n",
       "       [0.16436486, 0.83563507],\n",
       "       [0.8699817 , 0.13001828],\n",
       "       [0.85896504, 0.14103492],\n",
       "       [0.85369277, 0.14630719],\n",
       "       [0.8584707 , 0.1415293 ],\n",
       "       [0.16238214, 0.8376179 ],\n",
       "       [0.84572506, 0.15427501],\n",
       "       [0.16757387, 0.83242613],\n",
       "       [0.49305794, 0.50694203],\n",
       "       [0.8506491 , 0.14935094],\n",
       "       [0.8629217 , 0.1370783 ],\n",
       "       [0.8639725 , 0.13602746],\n",
       "       [0.25339624, 0.7466038 ],\n",
       "       [0.69815105, 0.30184898],\n",
       "       [0.675864  , 0.32413602],\n",
       "       [0.15589857, 0.8441014 ],\n",
       "       [0.5778084 , 0.42219162],\n",
       "       [0.16474688, 0.8352531 ],\n",
       "       [0.26758417, 0.7324158 ],\n",
       "       [0.85498315, 0.14501683],\n",
       "       [0.1582591 , 0.8417409 ],\n",
       "       [0.8663237 , 0.13367628],\n",
       "       [0.23117122, 0.7688288 ],\n",
       "       [0.7442479 , 0.25575212],\n",
       "       [0.83634555, 0.16365446],\n",
       "       [0.86780506, 0.13219492],\n",
       "       [0.28521046, 0.71478957],\n",
       "       [0.8654328 , 0.13456717],\n",
       "       [0.87616783, 0.12383212],\n",
       "       [0.82957125, 0.17042877],\n",
       "       [0.8244321 , 0.17556792],\n",
       "       [0.85369396, 0.14630604],\n",
       "       [0.8702899 , 0.12971012],\n",
       "       [0.58594215, 0.41405788],\n",
       "       [0.72041464, 0.2795854 ],\n",
       "       [0.8567969 , 0.1432031 ],\n",
       "       [0.86291265, 0.13708735],\n",
       "       [0.87005985, 0.1299402 ],\n",
       "       [0.5623652 , 0.43763486],\n",
       "       [0.87136906, 0.12863098],\n",
       "       [0.8558796 , 0.14412041],\n",
       "       [0.25823268, 0.7417673 ],\n",
       "       [0.8663757 , 0.13362432],\n",
       "       [0.3464959 , 0.6535041 ],\n",
       "       [0.15244037, 0.84755963],\n",
       "       [0.32591543, 0.6740846 ],\n",
       "       [0.26307082, 0.7369292 ],\n",
       "       [0.16195032, 0.83804965],\n",
       "       [0.75308764, 0.24691236],\n",
       "       [0.86997485, 0.1300252 ],\n",
       "       [0.8738028 , 0.12619726],\n",
       "       [0.2876718 , 0.71232826],\n",
       "       [0.36576155, 0.6342385 ],\n",
       "       [0.27066597, 0.72933406],\n",
       "       [0.87336856, 0.12663142],\n",
       "       [0.16857617, 0.8314238 ],\n",
       "       [0.16271468, 0.83728534],\n",
       "       [0.77385384, 0.22614618],\n",
       "       [0.15217438, 0.84782565],\n",
       "       [0.15726656, 0.8427334 ],\n",
       "       [0.5508131 , 0.44918692],\n",
       "       [0.22922549, 0.7707745 ],\n",
       "       [0.15896362, 0.8410364 ],\n",
       "       [0.58937085, 0.41062915],\n",
       "       [0.8567005 , 0.14329956],\n",
       "       [0.87460166, 0.12539831],\n",
       "       [0.16760276, 0.8323972 ],\n",
       "       [0.84947264, 0.15052736],\n",
       "       [0.8657097 , 0.1342902 ],\n",
       "       [0.86778927, 0.1322108 ],\n",
       "       [0.86709785, 0.13290215],\n",
       "       [0.2643023 , 0.73569775],\n",
       "       [0.26592404, 0.734076  ],\n",
       "       [0.78415596, 0.21584402],\n",
       "       [0.1632402 , 0.8367598 ],\n",
       "       [0.570474  , 0.42952594],\n",
       "       [0.8210636 , 0.1789364 ],\n",
       "       [0.85369396, 0.14630604],\n",
       "       [0.44054148, 0.55945855],\n",
       "       [0.3414295 , 0.6585705 ],\n",
       "       [0.8567688 , 0.14323117],\n",
       "       [0.8620836 , 0.13791634],\n",
       "       [0.86901927, 0.13098072],\n",
       "       [0.85896504, 0.14103492],\n",
       "       [0.26451445, 0.7354855 ],\n",
       "       [0.588214  , 0.411786  ],\n",
       "       [0.23016931, 0.7698307 ],\n",
       "       [0.8447977 , 0.15520231],\n",
       "       [0.26403812, 0.73596185],\n",
       "       [0.66427994, 0.33572003],\n",
       "       [0.17453644, 0.82546353],\n",
       "       [0.34774235, 0.6522576 ],\n",
       "       [0.2598641 , 0.74013585],\n",
       "       [0.15620662, 0.8437934 ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_keras = keras_model.predict(np.array(X_test))\n",
    "y_pred_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_keras_binary = [1 if x[1] > 0.5 else 0 for x in y_pred_keras]\n",
    "y_pred_keras_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7953488372093023\n",
      "Recall: 0.7654320987654321\n",
      "Precision: 0.7126436781609196\n",
      "Confusion matrix:\n",
      "[[109  25]\n",
      " [ 19  62]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_keras_binary))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, y_pred_keras_binary))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred_keras_binary))\n",
    "print(\"Confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred_keras_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. MapReduce (Lecture 13)\n",
    "\n",
    "All exercises from Lecture 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Time Series Analysis (Lecture 14 & 15)\n",
    "\n",
    "Do a time series analysis of the Copenhagen ice cream dataset (\"cph_ice_cream_searches.csv\") from Lectures 14 and 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. IoT (Lecture 17)\n",
    "\n",
    "All exercises from Lecture 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
